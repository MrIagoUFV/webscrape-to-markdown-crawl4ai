# Webscrape to Markdown - Crawl4AI

Ferramenta Python para fazer web scraping de pÃ¡ginas e converter automaticamente para markdown. Suporta tanto scraping de pÃ¡gina Ãºnica quanto mÃºltiplas pÃ¡ginas via sitemap.xml.

## ğŸš€ Funcionalidades

- Scraping de pÃ¡gina Ãºnica com salvamento automÃ¡tico no clipboard
- Scraping de mÃºltiplas pÃ¡ginas via sitemap.xml
- ConversÃ£o automÃ¡tica para markdown
- Gerenciamento de memÃ³ria e processamento paralelo
- Cache inteligente para otimizaÃ§Ã£o

## ğŸ“‹ PrÃ©-requisitos

```bash
# Instale as dependÃªncias
pip install -r requirements.txt

# Instale o playwright (necessÃ¡rio para o crawl4ai)
playwright install
```

## ğŸ¯ Como Usar

### Scraping de PÃ¡gina Ãšnica

```python
# Execute o script
python codigos/uma_pagina.py
```

O conteÃºdo serÃ¡ automaticamente convertido para markdown e copiado para seu clipboard.

### Scraping de MÃºltiplas PÃ¡ginas

```python
# Execute o script
python codigos/multiplas_paginas.py
```

1. Digite a URL do sitemap quando solicitado
2. O script irÃ¡:
   - Extrair todas as URLs do sitemap
   - Processar as pÃ¡ginas em paralelo
   - Salvar os arquivos markdown na pasta `/docs`
   - Gerar um README.md na pasta `/docs` com links para todas as pÃ¡ginas processadas

## ğŸ“ Estrutura do Projeto

```
.
â”œâ”€â”€ codigos/
â”‚   â”œâ”€â”€ uma_pagina.py           # Script para pÃ¡gina Ãºnica
â”‚   â”œâ”€â”€ multiplas_paginas.py    # Script para mÃºltiplas pÃ¡ginas
â”‚   â””â”€â”€ multiplas_paginas_manual.py
â”œâ”€â”€ docs/                       # Arquivos markdown gerados
â”œâ”€â”€ requirements.txt            # DependÃªncias do projeto
â””â”€â”€ README.md                   # Este arquivo
```

## ğŸ› ï¸ Tecnologias Utilizadas

- Python
- crawl4ai
- playwright
- psutil
- pyperclip

## âš™ï¸ ConfiguraÃ§Ãµes

O projeto inclui configuraÃ§Ãµes otimizadas para:
- Processamento paralelo (mÃ¡ximo de 10 pÃ¡ginas simultÃ¢neas)
- Gerenciamento automÃ¡tico de memÃ³ria
- Modo headless do navegador
- Sistema de cache inteligente
